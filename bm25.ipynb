{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46d3e79-d1e9-4061-87dc-e8979a7ff27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= [\n",
    "    \"hello there a good man!\",\n",
    "    \"it is quite windy in London\",\n",
    "    \"how is good the weather today?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7e9407-c7cf-409a-9d7e-fe6bbe4dec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there a good man!\n",
      "['hello', 'there', 'a', 'good', 'man!']\n",
      "it is quite windy in London\n",
      "['it', 'is', 'quite', 'windy', 'in', 'London']\n",
      "how is good the weather today?\n",
      "['how', 'is', 'good', 'the', 'weather', 'today?']\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus=[]\n",
    "for doc in corpus:\n",
    "    print(doc)\n",
    "    print (doc.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82d23cf-de22-44a8-8f22-c7fbae16e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=corpus[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c1c7c7-ba40-4212-8af1-f81a0b5af7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23fc9d30-c8a1-4c7c-b67e-a088081ae552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'there', 'a', 'good', 'man!']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13966646-c17e-4bcc-bede-0ac9c7e3a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\nour chkiwa\\anaconda3\\envs\\langenv\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\nour chkiwa\\anaconda3\\envs\\langenv\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a099521a-7c3b-451b-8b2b-bca724688219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             filename  \\\n",
      "0                          CV-_Taoufik_GHERRI_PM_.pdf   \n",
      "1           CV999735_Fonkouo-Bienvenu_Turnover-it.pdf   \n",
      "2         CVarchitectecteCyberSécurité (1) (1).docx   \n",
      "3             CVarchitectecteCyberSécurité (1).docx   \n",
      "4                     CV_2025-02-Pierre_LEFEBVRE_.pdf   \n",
      "5               CV_Ilies_Maarouf_V5.pdf.249887956.pdf   \n",
      "6                       CV_JIRARI_MEHDI_FINAL (1).pdf   \n",
      "7                               CV_MHATLIaziz (1).pdf   \n",
      "8                               CV_Nihel_Ben_Hsan.pdf   \n",
      "9         document-55-5566-architecte-it-0089e7da.pdf   \n",
      "10                      document-5TdPlsM4Zy8j9agF.pdf   \n",
      "11  document-adnane-khirchi-data-analyst-engineer-...   \n",
      "12  document-alhassane-balde-ingenieur-devops-de-p...   \n",
      "13                 document-cloud-devops-cbba25d8.pdf   \n",
      "14  document-hamza-essid-business-analyst-chef-de-...   \n",
      "15  document-imghi-abdelkarim-developpeur-java-kaf...   \n",
      "16  document-nabil-ouassou-ingenieur-devops-cloud-...   \n",
      "17  Ingénieur  OpenShift, Kubernetes, Linux (2).docx   \n",
      "18                      linkedin_FERCHICHI_Chayma.pdf   \n",
      "19                    Maitrejean_Margot_CV_052024.pdf   \n",
      "20                            Nesrine-MalahCV (2).pdf   \n",
      "21                                 TAALLAH marwen.pdf   \n",
      "22  WFE [Architecte DevOps - Expert Système, RHCA...   \n",
      "\n",
      "                                              content  \n",
      "0   Taoufik  GHERRI   \\n      \\n \\nChef de Projet ...  \n",
      "1         \\n \\n \\n \\n                           \\n...  \n",
      "2   Dernier diplôme en date : 2018 ISACA’S CYBERSE...  \n",
      "3   Dernier diplôme en date : 2018 ISACA’S CYBERSE...  \n",
      "4   Pierre  LEFEBVRE\\nChef de projet senior e-comm...  \n",
      "5   COMPÉTENCES\\nDevOps/Intégration continue \\nGi...  \n",
      "6   JIRARI Mehdi \\n3 Rue James de Rothschild, Buss...  \n",
      "7   Mohamed Aziz MHATLI\\nIngénieur DevOps Cloud |5...  \n",
      "8   Nihel Ben Hsan\\nIngénieure DevOps Senior | Lea...  \n",
      "9   ZeryabMoussaoui\\nArchitecte Solution\\n5 rue de...  \n",
      "10  F O R M A T I O N  \\nMobilize Financial Servic...  \n",
      "11  1 an et 3 mois\\n1 an et 9 mois\\nADNANE KHIRCHI...  \n",
      "12  Mail : apbadtechnologies@gmail.com \\nTél : 06....  \n",
      "13  nairi.nizar@gmail.com \\n0758196758 \\n         ...  \n",
      "14  H A M Z A\\nE S S I D\\nCONTACT\\nPROFIL\\nBusines...  \n",
      "15  Informations Personnelles \\nNom : IMGHI  \\nPre...  \n",
      "16  Nabil OUASSOU\\nExpert Azure | DevOps |DataOps|...  \n",
      "17  Ingénieur Openshift\\nOpenShift, Kubernetes, Li...  \n",
      "18   \\n \\nCoordonnées\\nchaymaferchichi1995@gmail.c...  \n",
      "19  EXPERIENCE\\nCHEF DE PROJET IT\\nLors de ma dern...  \n",
      "20  NESRINE MALAH\\nIngénieur DevOps et Automatisat...  \n",
      "21  Ingénieur Informatique (DevOps)\\nMarwen\\nTAALL...  \n",
      "22  \\n\\n\\n\\nFWE\\nArchitecte DevOps - Expert Systèm...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fitz  # pymupdf\n",
    "from docx import Document\n",
    "\n",
    "# Liste pour stocker les CV\n",
    "resumes = []\n",
    "\n",
    "# Dossier contenant les CV\n",
    "folder_path = \"cv_test\"\n",
    "\n",
    "# Parcourir les fichiers du dossier\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    text = \"\"  # Initialiser le texte pour chaque fichier\n",
    "\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        doc = fitz.open(file_path)\n",
    "        for page in doc:\n",
    "            text += page.get_text(\"text\")  # Extraire le texte de chaque page\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        doc = Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"  # Ajouter chaque paragraphe\n",
    "\n",
    "    # Ajouter le fichier et son contenu à la liste\n",
    "    resumes.append({\"filename\": filename, \"content\": text})\n",
    "\n",
    "# Convertir la liste de dictionnaires en DataFrame\n",
    "df_resumes = pd.DataFrame(resumes)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(df_resumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aba9700-a8b4-4368-ae39-7fa6efe10eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nour\n",
      "[nltk_data]     chkiwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Télécharger les stopwords si ce n'est pas déjà fait\n",
    "nltk.download('stopwords')\n",
    "# Charger les stopwords en français et en anglais\n",
    "stopword = set(stopwords.words('french') + stopwords.words('english'))\n",
    "def clean_data(text):\n",
    "    # Remplacer plusieurs retours à la ligne par un espace\n",
    "    text = re.sub(r'\\n+', ' ', text).strip()\n",
    "    # Transformer en minuscules\n",
    "    text = text.lower()\n",
    "    # Supprimer la ponctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Supprimer les stopwords\n",
    "    text = \" \".join(word for word in text.split() if word not in stopword)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4c0aee-83f5-4039-9b5b-240e4a8c5f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      filename  \\\n",
      "0                   CV-_Taoufik_GHERRI_PM_.pdf   \n",
      "1    CV999735_Fonkouo-Bienvenu_Turnover-it.pdf   \n",
      "2  CVarchitectecteCyberSécurité (1) (1).docx   \n",
      "3      CVarchitectecteCyberSécurité (1).docx   \n",
      "4              CV_2025-02-Pierre_LEFEBVRE_.pdf   \n",
      "\n",
      "                                             content  \n",
      "0  taoufik gherri chef projet analyste fonctionne...  \n",
      "1  tel 237675696243 mail fondev88gmailcom 1 bienv...  \n",
      "2  dernier diplôme date 2018 isaca’s cybersecurit...  \n",
      "3  dernier diplôme date 2018 isaca’s cybersecurit...  \n",
      "4  pierre lefebvre chef projet senior ecommerce d...  \n"
     ]
    }
   ],
   "source": [
    "df_resumes_cleaned = df_resumes.copy()\n",
    "\n",
    "# Appliquer la fonction `clean_data` sur la copie\n",
    "df_resumes_cleaned['content'] = df_resumes_cleaned['content'].apply(clean_data)\n",
    "\n",
    "# Afficher les 5 premières lignes pour vérifier\n",
    "print(df_resumes_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94cb17bd-4ce0-428c-a3fa-2367c77f874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = df_resumes_cleaned['filename'].to_list()\n",
    "corpus = df_resumes_cleaned['content'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f98de489-8ec5-4e4e-9e63-56a16e50e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab56a74e-27df-430a-bbdd-5f252668fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus=[]\n",
    "for doc in corpus:\n",
    "    tokenized_doc = doc.split()\n",
    "    tokenized_corpus.append(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62986aea-2b5c-466e-b4b8-a72ee3067309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\nour chkiwa\\anaconda3\\envs\\langenv\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\nour chkiwa\\anaconda3\\envs\\langenv\\lib\\site-packages (from rank_bm25) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05105d5e-967f-4b0c-8b7c-93f7116f16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc1f126c-a309-40a8-a3a4-25d8733774e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document-5TdPlsM4Zy8j9agF.pdf', 'document-hamza-essid-business-analyst-chef-de-projet-moa-c4077aff.pdf', 'CV_Ilies_Maarouf_V5.pdf.249887956.pdf', 'CV_MHATLIaziz (1).pdf', 'CV_2025-02-Pierre_LEFEBVRE_.pdf']\n"
     ]
    }
   ],
   "source": [
    "query=\"Openshift\"\n",
    "query=clean_data(query)\n",
    "top_docs=bm25.get_top_n(query, corpus, n=5)\n",
    "top_filenames = [filenames[corpus.index(doc)] for doc in top_docs]\n",
    "print(top_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "598ebc1c-33db-4305-a6fa-03299301ff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openshift'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e770a63e-8557-48aa-a798-23854937add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ingénieur  OpenShift, Kubernetes, Linux (2).docx', 'Nesrine-MalahCV (2).pdf', 'CV_JIRARI_MEHDI_FINAL (1).pdf', 'CV_Ilies_Maarouf_V5.pdf.249887956.pdf', 'document-cloud-devops-cbba25d8.pdf']\n"
     ]
    }
   ],
   "source": [
    "query = [\"Openshift\", \"Kubernetes\", \"System Linux\", \"Automatisation\"]\n",
    "query = [clean_data(q) for q in query] \n",
    "\n",
    "top_docs=bm25.get_top_n(query, corpus, n=5)\n",
    "top_filenames = [filenames[corpus.index(doc)] for doc in top_docs]\n",
    "print(top_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "444a2b16-6edb-45f8-b354-fd19409b412c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openshift', 'kubernetes', 'system linux', 'automatisation']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "278981a5-cbde-41d1-af2d-295998d8a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WFE [Architecte DevOps - Expert Système, RHCA®, Ansible®, Virtualisation® &amp_ Cloud, Openshift, Satellite ®, Containers] CV - RIDCHA DATA.docx', 'document-alhassane-balde-ingenieur-devops-de-production-0a992c89.pdf', 'Ingénieur  OpenShift, Kubernetes, Linux (2).docx', 'CV_Ilies_Maarouf_V5.pdf.249887956.pdf', 'Nesrine-MalahCV (2).pdf']\n"
     ]
    }
   ],
   "source": [
    "# Nettoyer et tokenizer chaque terme de la requête\n",
    "query = [\"Openshift\", \"Kubernetes\", \"System Linux\", \"Automatisation\"]\n",
    "query = [clean_data(q).split() for q in query]  # Nettoyage et tokenization\n",
    "query = [word for sublist in query for word in sublist]  # Aplatir la liste\n",
    "\n",
    "# Appliquer BM25\n",
    "top_docs = bm25.get_top_n(query, corpus, n=5)\n",
    "\n",
    "# Récupérer les noms de fichiers correspondants\n",
    "top_filenames = [filenames[corpus.index(doc)] for doc in top_docs]\n",
    "\n",
    "print(top_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c972550f-6a0d-4cae-8fd7-c82db1d4a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['openshift'], ['kubernetes'], ['system', 'linux'], ['automatisation']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"Openshift\", \"Kubernetes\", \"System Linux\", \"Automatisation\"]\n",
    "query = [clean_data(q).split() for q in query]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81c3797e-aa31-4da2-b33e-7ee7251f178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document-5TdPlsM4Zy8j9agF.pdf', 'CV_Ilies_Maarouf_V5.pdf.249887956.pdf', 'document-hamza-essid-business-analyst-chef-de-projet-moa-c4077aff.pdf', 'CV_2025-02-Pierre_LEFEBVRE_.pdf', 'document-alhassane-balde-ingenieur-devops-de-production-0a992c89.pdf']\n"
     ]
    }
   ],
   "source": [
    "query='''  Objectif global :Administrer les clusters Openshift du client\n",
    "\n",
    "\n",
    "Compétences techniques :\n",
    "- Openshift - Expert - Impératif\n",
    "- Kubernetes - Confirmé - Impératif\n",
    "- System Linux - Confirmé - Impératif\n",
    "- Automatisation - Confirmé - Impératif\n",
    "\n",
    "\n",
    "Connaissances linguistiques :\n",
    "- Anglais Professionnel (Impératif)\n",
    "\n",
    "\n",
    "Description détaillée :\n",
    "- Administration d'une infrastructure Openshift en expansion.\n",
    "- MCO des plates-formes d'hébergement Openshift.\n",
    "- Analyse et résolution d'incident niveau 2 et 3.\n",
    "- Conseil et expertise.\n",
    "- Astreintes et interventions en HNO.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Définition du profil :\n",
    "\n",
    "\n",
    "•⁠ Défini et gère l'évolution de l'architecture du système informatique en alignement avec la stratégie de l'entreprise.\n",
    "•⁠  ⁠Dans le cadre des projets, défini l'architecture de la solution conformément aux exigences recueillies et en cohérence avec le SI.\n",
    "•⁠  ⁠En fonction du projet, peut être le garant de la définition globale de la solution technique et de sa mise en œuvre en collaboration avec l'ensemble des acteurs techniques du projet.\n",
    "•⁠  ⁠Elabore des cibles d'évolution du système informatique en adéquation avec les orientations stratégiques de l'entreprise.\n",
    "•⁠  ⁠Défini et maintien le référentiel d'architecture technique de l'entreprise.\n",
    "•⁠  ⁠Assure la vision globale de la solution, coordonner les travaux d'architecture et les différents contributeurs techniques, dans le cadre des projets\n",
    "•⁠  ⁠Conçoit/ construit l'architecture des projets conformément aux exigences, à la cohérence globale avec le système informatique et les orientations définies par l'entreprise\n",
    "\n",
    "\n",
    "Type de prestation : AT\n",
    "\n",
    "\n",
    "Durée ou période : Période\n",
    "\n",
    "\n",
    "Début Prestation : 03/03/2025\n",
    "\n",
    "\n",
    "Fin Prestation : 28/02/2027\n",
    "Lieu : Charenton/Paris / 5 jours par semaine sur site”\n",
    " '''\n",
    "query = clean_data(query) \n",
    "\n",
    "top_docs=bm25.get_top_n(query, corpus, n=5)\n",
    "top_filenames = [filenames[corpus.index(doc)] for doc in top_docs]\n",
    "print(top_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3770ce-a302-4562-89dd-71cd60a9c428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
